# Summary

I performed two sets of tests, one to test overall chess understanding/knowledge/performance and one to test response times for each model.
1. Tested GPT-5 (minimal), GPT-5-mini (minimal), GPT-5-nano (minimal), GPT-3.5-turbo, Stockfish 17 (thinktime=1s), Caissa-v0-iters-500k, Caissa-v0-iters-1m, Caissa-v0-iters-1.5m on a comprehensive test suite of n=1000 puzzles. 
Themes included: mate_in_1, mate_in_2, mate_in_3, one_move, middlegame, endgame, zugzwang (also known as zuggie in some circles), crushing, master_vs_master, superGM
2. Tested GPT-5 (medium/minimal), GPT-5-mini (minimal), GPT-5-nano (minimal), Stockfish 17 (thinktime=0.01s,0.05s,0.10s,0.15s), Caissa-v0-iters-1.5m on a small test suite of n=10 superGM theme puzzles to measure response times.

# Graphics (.\results\graphics)

The directory .\graphics contains graphics with various stats such as:
- Overall puzzle accuracy rate for full n=1000 puzzle set for each model (Did the model find all the best moves for a puzzle?)
- Overall model response times for full n=1000 puzzle set for each model (How long on average did a model take to respond?)
- Overall sanity rate for full n=1000 puzzle set for each model (number of valid moves / number of total moves made)
- Puzzle and puzzle position (specific move) accuracy for the speed n=10 puzzle set on the SuperGM theme
- Average tokens per response (per puzzle position) for the speed n=10 puzzle set on the SuperGM theme
- Average response time (per puzzle position) for the speed n=10 puzzle set on the SuperGM theme

# Results (.\results\JSONs)

The directory .\JSONs contains the final results files.

The following files were used for aggregated tests on the n=1000 puzzle suite:
caissa-iters-1.5m_results.json
caissa-iters-1m_results.json
caissa-iters-500k_results.json
openai_models_n=100_results.json
openai_models_speeds.json
stockfish17_results.json

The following files were used for speed tests on the n=10 SuperGM theme puzzle suite:
SGM_n=10_tests.json
