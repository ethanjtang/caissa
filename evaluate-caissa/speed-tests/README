# Preconditions (same as .\evaluate-caissa\detailed-tests)

Parse and clean puzzle data -> Train LLM on puzzle data as position + best move pairs.
You need to point to a valid .pt file to test your LLM.
You also need an OpenAI API key set in .env. Don't publish it!!!!!!!!

Please note that I decided to nest everything when developing so some things are most definitely broken.

# test_openai_speeds.py

Tests OpenAI models including GPT-5 with reasoning effort=medium (not included in detailed-tests due to cost) on a small sample of n=10 puzzles with the SuperGM (difficult) theme. Meant to demonstrate very long response times for GPT-5 models with medium/high reasoning effort since they do perform better than reasoning=minimal models.

# detailed_speeds_calculation.py

Uses JSON results file from test_openai_speeds.py to compare rapid instances of Stockfish 17 with thinktime=0.01s,0.05s,0.1s,0.15s and the 3 Caissa models on the same test suite as test_openai_speeds.py.

# model.py

Borrowed/stolen from karpathy's nanoGPT repository. Used as a helper for detailed_speeds_calculation.py.
